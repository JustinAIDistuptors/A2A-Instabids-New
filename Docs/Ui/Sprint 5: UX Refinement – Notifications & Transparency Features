Sprint 5: UX Refinement – Notifications & Transparency Features
Deliverables: Enhance user experience by adding a notification system and advanced transparency features. Users will receive clear alerts/notifications for important agent events (errors, successes, or prompts requiring attention), and they will have options to get more insight into the agent’s decisions (e.g., an “Explain this” feature for AI actions). By the end of this sprint, the UI will be more interactive and user-friendly, with critical feedback loops in place.
Components & Files: Build new UI elements for notifications and agent transparency:
Notification/Alert System: Implement a global notification mechanism for the app:
Use a library or component for toasts – for example, integrate Sonner or use Shadcn UI’s toast primitives if available. Set up a ToastProvider (if using a library) in the root of the app (likely in app/layout.tsx or a context).
Create utility functions or hooks (e.g., useNotify()) that other parts of the app can call to trigger notifications. Notifications might include: informational (e.g., “New bid successfully created”), success (e.g., “Bid won!”), warning/error (e.g., “Agent lost connection” or “Error placing bid”).
Ensure different types of messages have distinct styles (colors, icons). Non-intrusive ones can auto-dismiss after a few seconds (toast), whereas critical ones might require user dismissal or an action (for example, using a modal dialog for confirmations).
For critical confirmations from the agent (if the agent needs user approval to proceed at some point), use Shadcn’s Alert Dialog component. For instance, if agent finds a deal and needs confirmation to purchase, pop an AlertDialog with details and “Confirm / Cancel” buttons.
Make sure the notification system is accessible (aria-live regions for toasts so screen readers are notified).
Agent Decision Transparency: Introduce UI affordances for explaining or clarifying agent actions:
For example, in the workflow timeline (from Sprint 4) or on bid details, add an “Explain” button/icon next to steps or outcomes. When clicked, this could trigger a modal or side panel showing the agent’s reasoning or the source of information for that step.
Implement a component AgentExplanation.tsx that can display an explanation text. This might call a backend endpoint (e.g., GET /agent/explain?stepId=X or similar) to retrieve the agent’s reasoning or data behind a decision. Alternatively, if such data is already being sent in events, perhaps store it and show it directly.
Also consider a knowledge source display: if the agent used external info (like market data or a specific knowledge base) to make a decision, show references or data snapshots. This could be as simple as listing URLs or data points in the explanation modal.
Integrate this feature into the UI where appropriate: for instance, if a bid failed or succeeded, an “Explain” option could explain why (outbid by someone, or criteria not met, etc., as provided by agent).
User Feedback Mechanism: Provide a way for the user to give feedback on the agent’s performance or the outcome:
This could be a quick rating prompt after a bid completes or a general feedback form. For instance, after an auction ends, show a thumbs-up/down or a 5-star rating component asking “How helpful was the agent in this task?”.
Create a FeedbackForm component (could be a dialog or a section in Settings) where users can submit comments or ratings. Hook this up to a backend endpoint (e.g., POST /feedback) so feedback is recorded.
Emphasize that this is optional for the user but valuable for continuous improvement.
Backend/Agent Integration: Align the new UX features with backend capabilities:
Notifications Triggers: Identify events where notifications are needed. Some will be triggered by frontend logic (e.g., upon successfully creating a bid, show a success toast). Others come from the backend (e.g., an error event from the agent or a completion event).
Utilize the event stream (from Sprint 4) or responses to trigger notifications. For example, if an event says a bid was won, show a celebratory notification. If the agent sends an error (like unable to place bid), display an alert with that message.
For agent queries requiring confirmation, define how the backend asks for it. Possibly the agent might pause and send a message “require_confirmation” via the chat or event stream. The frontend should catch that and show an AlertDialog with the relevant question, and then send the user’s choice back (perhaps via a POST to an endpoint or a response on the chat channel).
Explain Endpoint: Work with backend to implement an explanation feature. This might involve:
The agent storing trace information about decisions. The UI’s request (when user clicks explain) could retrieve this. For instance, a call to /agent/explanation?bidId=123&step=pricing that returns a JSON or text explanation of what the agent did or considered at that step.
If no dedicated endpoint, the fallback could be to use the chat: e.g., send a hidden prompt “Explain why you did X” to the agent and show the answer. However, a direct endpoint is more deterministic. Ensure security (the agent shouldn’t reveal sensitive info).
Feedback Submission: Ensure a backend route exists to collect feedback. If not, implement a temporary solution like sending it to a logging service or simply console logging it for now, but ideally POST to /feedback and have the backend store it (could be in a database or an email). No critical system impact, so it can be simple.
Continue to monitor that all these additions do not overwhelm the agent API; throttle or debounce calls as needed (e.g., don’t allow spamming the explain button to hit the backend repeatedly).
Tests: Verify that the UX enhancements work correctly and don’t regress core functionality:
Unit Tests:
Test the notification hook/utility: call the notify function with various types and ensure the correct toast appears (this might require abstracting the toast into a component that can be inspected). If using a context, test that pushing a notification adds it to the list.
Test the AgentExplanation component: if given a mock explanation text or when a certain prop (like stepId) is set, it fetches the explanation (mock the API call) and displays it. Ensure loading states or error states (if explanation fails to load) are handled (e.g., show “Unable to retrieve explanation”).
Test the FeedbackForm: simulate filling and submitting feedback. If it calls an API, mock it and ensure it was called with the input data, and that the form resets or shows a thank-you message afterward.
Integration Tests:
Trigger a known scenario to generate a notification. For example, use Cypress to stub a backend response that causes an error (like stub the /bids POST to return 500). Try submitting the BidForm and verify that an error toast appears. Likewise, stub a success and ensure a success toast.
Test the explain feature end-to-end: stub the explain endpoint. For instance, after a bid completes in a test, click the “Explain” button and have Cypress intercept the /agent/explanation request, return some dummy explanation text, and then check that the text shows up in the modal.
Test the feedback form end-to-end: fill it out and stub the /feedback submission to return 200, then check that the UI responds (maybe closes the modal or shows a thank-you).
Also ensure that normal chat and bid flows still work with these new features present (regression test).
Perform an accessibility test pass (using tools like axe or manual testing) on the new modals and toasts: ensure they are reachable by keyboard and announced by screen readers (toasts should have role="status" or similar).
DevOps & GitHub Actions: Use a branch (e.g. ui/ux-enhancements). As features are completed, commit with messages like feat(ui): add toast notification system and feat(ui): implement agent explanation modal.
The CI pipeline should run the expanded test suite. Pay attention that integration tests for things like toasts might be timing-sensitive; use appropriate waits in Cypress or mock the timing (e.g., set toast auto-close to longer during tests).
Before merging, perhaps deploy this branch to a staging environment for user-acceptance testing (UAT). Given these are user-facing enhancements, gather feedback from a few testers or stakeholders if possible, then iterate (commit any small UI tweaks).
Merge into main and confirm all CI checks and deployment. At this point, the UI should be feature-complete with respect to core functionality and UX, paving the way for final polish and launch.
